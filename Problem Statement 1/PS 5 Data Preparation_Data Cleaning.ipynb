{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc, os\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all quarter data\n",
    "q1_2017 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2017_Q1.csv')\n",
    "q2_2017 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2017_Q2.csv')\n",
    "q3_2017 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2017_Q3.csv')\n",
    "q4_2017 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2017_Q4.csv')\n",
    "\n",
    "q1_2018 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2018_Q1.csv')\n",
    "q2_2018 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2018_Q2.csv')\n",
    "q3_2018 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2018_Q3.csv')\n",
    "q4_2018 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2018_Q4.csv')\n",
    "\n",
    "q1_2019 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2019_Q1.csv')\n",
    "q2_2019 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2019_Q2.csv')\n",
    "q3_2019 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2019_Q3.csv')\n",
    "q4_2019 = pd.read_csv('C:/DPA Project/data/Divvy_Trips_2019_Q4.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Total Docks</th>\n",
       "      <th>Docks in Service</th>\n",
       "      <th>Status</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>675</td>\n",
       "      <td>HQ QR</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>In Service</td>\n",
       "      <td>41.889914</td>\n",
       "      <td>-87.680343</td>\n",
       "      <td>(41.88991358344108, -87.68034316599368)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>418</td>\n",
       "      <td>Ellis Ave &amp; 53rd St</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>In Service</td>\n",
       "      <td>41.799336</td>\n",
       "      <td>-87.600958</td>\n",
       "      <td>(41.79933626261, -87.6009581145)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "      <td>Montrose Harbor</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>In Service</td>\n",
       "      <td>41.963982</td>\n",
       "      <td>-87.638181</td>\n",
       "      <td>(41.963982, -87.638181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>322</td>\n",
       "      <td>Kimbark Ave &amp; 53rd St</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>In Service</td>\n",
       "      <td>41.799568</td>\n",
       "      <td>-87.594747</td>\n",
       "      <td>(41.799568, -87.594747)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>In Service</td>\n",
       "      <td>41.864059</td>\n",
       "      <td>-87.623727</td>\n",
       "      <td>(41.864059, -87.623727)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID            Station Name  Total Docks  Docks in Service      Status  \\\n",
       "0  675                   HQ QR            7                 7  In Service   \n",
       "1  418     Ellis Ave & 53rd St           11                11  In Service   \n",
       "2  249         Montrose Harbor           31                31  In Service   \n",
       "3  322   Kimbark Ave & 53rd St           19                19  In Service   \n",
       "4  168  Michigan Ave & 14th St           19                19  In Service   \n",
       "\n",
       "    Latitude  Longitude                                 Location  \n",
       "0  41.889914 -87.680343  (41.88991358344108, -87.68034316599368)  \n",
       "1  41.799336 -87.600958         (41.79933626261, -87.6009581145)  \n",
       "2  41.963982 -87.638181                  (41.963982, -87.638181)  \n",
       "3  41.799568 -87.594747                  (41.799568, -87.594747)  \n",
       "4  41.864059 -87.623727                  (41.864059, -87.623727)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Station Data\n",
    "\n",
    "station_data = pd.read_csv(\"C:/DPA Project/data/Divvy_Bicycle_Stations.csv\")\n",
    "station_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename q1_2018 & q2_2019 columns to match others\n",
    "q1_2018.rename(columns={'01 - Rental Details Rental ID':'trip_id', '01 - Rental Details Local Start Time':'start_time','01 - Rental Details Local End Time':'end_time','01 - Rental Details Bike ID':'bikeid','01 - Rental Details Duration In Seconds Uncapped':'tripduration','03 - Rental Start Station ID':'from_station_id', '03 - Rental Start Station Name':'from_station_name','02 - Rental End Station ID':'to_station_id','02 - Rental End Station Name':'to_station_name', 'User Type':'usertype', 'Member Gender':'gender','05 - Member Details Member Birthday Year':'birthyear'}, inplace=True)\n",
    "\n",
    "q2_2019.rename(columns={'01 - Rental Details Rental ID':'trip_id', '01 - Rental Details Local Start Time':'start_time','01 - Rental Details Local End Time':'end_time','01 - Rental Details Bike ID':'bikeid','01 - Rental Details Duration In Seconds Uncapped':'tripduration','03 - Rental Start Station ID':'from_station_id', '03 - Rental Start Station Name':'from_station_name','02 - Rental End Station ID':'to_station_id','02 - Rental End Station Name':'to_station_name', 'User Type':'usertype', 'Member Gender':'gender','05 - Member Details Member Birthday Year':'birthyear'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate all 3 years of data\n",
    "df = pd.concat([q1_2017, q2_2017, q3_2017, q4_2017,q1_2018, q2_2018, q3_2018, q4_2018, q1_2019,q2_2019,q3_2019,q4_2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column\n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(4)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 12 columns.\n",
      "There are 2 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>gender</td>\n",
       "      <td>1958538</td>\n",
       "      <td>17.4091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>birthyear</td>\n",
       "      <td>1930718</td>\n",
       "      <td>17.1618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Missing Values  % of Total Values\n",
       "gender            1958538            17.4091\n",
       "birthyear         1930718            17.1618"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11250100, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Total Docks, To Latitude & To Longitude Data in Dataframe\n",
    "df['total_docks'] =  df['from_station_id'].map(station_data.set_index('ID')['Total Docks'])\n",
    "df['to_latitude'] = df['to_station_id'].map(station_data.set_index('ID')['Latitude'])\n",
    "df['to_longitude'] = df['to_station_id'].map(station_data.set_index('ID')['Longitude'])\n",
    "df['from_latitude'] = df['from_station_id'].map(station_data.set_index('ID')['Latitude'])\n",
    "df['from_longitude'] = df['from_station_id'].map(station_data.set_index('ID')['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculating Distnace between origin and destination using lat long\n",
    "\n",
    "from pyproj import Geod\n",
    "\n",
    "wgs84_geod = Geod(ellps='WGS84') #Distance will be measured on this ellipsoid - more accurate than a spherical method\n",
    "\n",
    "#Get distance between pairs of lat-lon points\n",
    "def Distance(lat1,lon1,lat2,lon2):\n",
    "  az12,az21,dist = wgs84_geod.inv(lon1,lat1,lon2,lat2) #Yes, this order is correct\n",
    "  return dist\n",
    "df['dist_mts'] = Distance(df['to_latitude'].tolist(),df['to_longitude'].tolist(),df['from_latitude'].tolist(),df['from_longitude'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correcting the data type of tripduration field testing dataset\n",
    "df['tripduration'] = df['tripduration'].str.replace(',', '')\n",
    "df['tripduration'] = df['tripduration'].apply(lambda x:float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tripduration'] = pd.to_numeric(df['tripduration'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding revenue column basis tripduration charging $3/ 30 minutes ride\n",
    "df['revenue'] = (df['tripduration']/1800) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.125010e+07\n",
       "mean     1.904959e+02\n",
       "std      1.437865e+02\n",
       "min      1.000000e+00\n",
       "25%      7.600000e+01\n",
       "50%      1.650000e+02\n",
       "75%      2.840000e+02\n",
       "max      6.730000e+02\n",
       "Name: from_station_id, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['from_station_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the number of check-outs per station\n",
    "station_counts_from = pd.DataFrame(df['from_station_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the number of check-ins per station\n",
    "station_counts_to= pd.DataFrame(df['to_station_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a DataFrame with the check-outs and check-ins\n",
    "## Create a columns that sums check-outs and check-ins\n",
    "station_counts = pd.concat([station_counts_from, station_counts_to], axis=1)\n",
    "station_counts.rename(columns={'from_station_id':'checkouts', 'to_station_id':'checkins'}, inplace=True)\n",
    "station_counts['total'] = station_counts['checkouts'] + station_counts['checkins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After some research, we will use the top stations with checkin+checkout >50,000\n",
    "## Stations have a total > 50,000\n",
    "station_counts_50k = station_counts[station_counts.total>50000]\n",
    "stations = list(station_counts_50k.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract just trips that involve the stations with total checkin checkout > 50K in the model\n",
    "q2_stations = df[(df['from_station_id'].isin(stations)) | (df['to_station_id'].isin(stations))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## Convert the 'start_time' column to a datetime object\n",
    "q2_stations['start_time'] = pd.to_datetime(q2_stations['start_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows with any NaN and NaT values\n",
    "#q2_stations = q2_stations.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "q2_stations['trips'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "q2_stations['year'] = pd.DatetimeIndex(q2_stations['start_time']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "q2_stations['month'] = pd.DatetimeIndex(q2_stations['start_time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "q2_stations['week'] = pd.DatetimeIndex(q2_stations['start_time']).week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "q2_stations['weekday'] = q2_stations['start_time'].apply(lambda x: x.strftime(\"%A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "q2_stations['week_number_of_year'] = q2_stations['start_time'].dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "q2_stations['hour'] = pd.DatetimeIndex(q2_stations['start_time']).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_stations.to_csv('C:/DPA Project/result1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trip_id                         int64\n",
       "start_time             datetime64[ns]\n",
       "end_time                       object\n",
       "bikeid                          int64\n",
       "tripduration                  float64\n",
       "from_station_id                 int64\n",
       "from_station_name              object\n",
       "to_station_id                   int64\n",
       "to_station_name                object\n",
       "usertype                       object\n",
       "gender                         object\n",
       "birthyear                     float64\n",
       "total_docks                   float64\n",
       "to_latitude                   float64\n",
       "to_longitude                  float64\n",
       "from_latitude                 float64\n",
       "from_longitude                float64\n",
       "dist_mts                      float64\n",
       "revenue                       float64\n",
       "year                            int64\n",
       "month                           int64\n",
       "trips                           int64\n",
       "week                            int64\n",
       "weekday                        object\n",
       "week_number_of_year             int64\n",
       "hour                            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_stations.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
